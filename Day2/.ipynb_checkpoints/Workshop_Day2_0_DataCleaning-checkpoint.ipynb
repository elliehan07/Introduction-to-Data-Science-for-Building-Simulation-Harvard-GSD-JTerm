{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J-Term 2017, Harvard GSD :\n",
    "### Introduction to Data Science for Building Simulation\n",
    "***\n",
    "Instructor: Jung Min Han, elliehan07@gmail.com <br>\n",
    "Teaching Assistant: NJ Namju Lee, nj.namju@gmail.com <br>\n",
    "Date/Time: Jan 9-12/ 1:00 - 3:00 p.m. <br>\n",
    "Location: 20 Sumner/Room 1-D<br>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.stats import mode\n",
    "from sklearn import linear_model\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import discriminant_analysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, random\n",
    "import sklearn\n",
    "print sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetPandasFromFileCSV(path):\n",
    "    return pd.read_csv(path, delimiter=',')\n",
    "\n",
    "def GetPandasFromFile(path, theSkipRow):\n",
    "    return pd.read_csv(path, skiprows= theSkipRow , header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = GetPandasFromFileCSV(\"data/_RentPriceTruliaMergeFinal.csv\")\n",
    "# print df.shape\n",
    "# print df.head(3)\n",
    "# print df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EllieHan\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:1: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data = df.convert_objects(convert_numeric=True)\n",
    "\n",
    "to_float = []\n",
    "to_encode = []\n",
    "for col in data.columns:\n",
    "    if data[col].dtype =='object':\n",
    "        to_encode.append(col);\n",
    "    if data[col].dtype =='int64':\n",
    "        to_float.append(col);\n",
    "#     print col,data[col].dtype\n",
    "        \n",
    "# print to_float\n",
    "# print \"----------------------\"\n",
    "# print to_encode\n",
    "\n",
    "for feature_name in to_float:\n",
    "    data[feature_name] = data[feature_name].astype(float)\n",
    "\n",
    "def encode_categorical(array):\n",
    "    if not array.dtype == np.dtype('float64'):\n",
    "        return preprocessing.LabelEncoder().fit_transform(array) \n",
    "    else:\n",
    "        return array\n",
    "    \n",
    "# Categorical columns for use in one-hot encoder\n",
    "categorical = (data.dtypes.values != np.dtype('float64'))\n",
    "\n",
    "# Encode all labels\n",
    "data = data.apply(encode_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixelPlant 0\n",
      "pixelPole 0\n",
      "pixelLake 0\n",
      "pixelRoad 0\n",
      "pixelGrass 0\n",
      "pixelWall 0\n",
      "pixelCar 0\n",
      "propertiesAsses 0\n",
      "pixelSea 0\n",
      "numCraigslistHouse 0\n",
      "pixelRiver 0\n",
      "pixelBus 0\n",
      "pixelCeiling 0\n",
      "pixelPath 0\n",
      "pixelBuilding 0\n",
      "crime 0\n",
      "pixelFence 0\n",
      "walkSchool 0\n",
      "walkMbta 0\n",
      "energySiteEUI 0\n",
      "pixelPerson 0\n",
      "pixelTree 0\n",
      "pixelVan 0\n",
      "walkPark 0\n",
      "walkUniversity 0\n",
      "pixelSidewalk 0\n",
      "pixelGround 0\n",
      "pixelMountain 0\n",
      "pixelPalmTree 0\n",
      "pixelHouse 0\n",
      "pixelBridge 0\n",
      "pixelSign 0\n",
      "pixelRailing 0\n",
      "pixelField 0\n",
      "pixelWindow 0\n",
      "pixelGrandstand 0\n",
      "numCraigslistRoom 0\n",
      "pixelSky 0\n",
      "Latitude 0\n",
      "Longitude 0\n",
      "Address 0\n",
      "Zip 0\n",
      "RoomType 995\n",
      "Bathrooms 125\n",
      "SQFT 8630\n",
      "SQM 0\n",
      "Price 27\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print col,len(df[df[col].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deleting Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before processing NAN :  (13049, 47)\n",
      "after processing NAN : (4176, 48)\n"
     ]
    }
   ],
   "source": [
    "def RemoveRowWithNAN(data):\n",
    "    data = data.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "    return data.reset_index()\n",
    "\n",
    "def RemoveColumnsWithNull(data, num):\n",
    "    complete_cols = [column for column in data.columns if len(data[column][data[column].isnull()]) < num]\n",
    "    return data[complete_cols]\n",
    "\n",
    "def ReomveRowwithNANWithNum(data):\n",
    "    data = data.dropna(thresh=None)\n",
    "    return data\n",
    "\n",
    "def GetNumpyColumnFromIndex(theDF):\n",
    "    theD = pd.DataFrame(theDF.values);\n",
    "    return theD.as_matrix()\n",
    "\n",
    "def CheckPandasNAN(data):\n",
    "    theResult = pd.isnull(data)\n",
    "    count = 0;\n",
    "    for i in theResult:\n",
    "        if(i == True): count+=1\n",
    "    return \"the number of NAN is :\" , count\n",
    "\n",
    "print \"before processing NAN : \", df.shape\n",
    "\n",
    "data.dropna(axis=0,subset=['RoomType','Price','Bathrooms'],inplace=True)\n",
    "\n",
    "## deal with the NAN data !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "df_new = RemoveRowWithNAN(df)\n",
    "\n",
    "# df_new = df_new.convert_objects(convert_numeric=True)\n",
    "df_new = ReomveRowwithNANWithNum(df_new)\n",
    "\n",
    "print \"after processing NAN :\", df_new.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=4\n",
    "knntest = data[data['SQFT'].isnull()]\n",
    "knntrain = data[data['SQFT'].isnull()==False]\n",
    "\n",
    "xknn_train = knntrain[['RoomType','Bathrooms','Longitude','Latitude','Zip']].values\n",
    "yknn_train = knntrain['SQFT'].values\n",
    "\n",
    "xknn_test = knntest[['RoomType','Bathrooms','Longitude','Latitude','Zip']].values\n",
    "neighbours = KNN(n_neighbors=k)\n",
    "neighbours.fit(xknn_train, yknn_train)\n",
    "yknn_test = neighbours.predict(xknn_test)\n",
    "\n",
    "my_df = data.set_value( data['SQFT'].isnull(),'SQFT',yknn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in my_df.columns:\n",
    "    print col,len(my_df[my_df[col].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_drop = my_df.drop('Address',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_drop.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_iloc = df_drop.iloc[:,7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_iloc['pixelWater'] = df_iloc['pixelRiver']+df_iloc['pixelSea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_iloc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_iloc.rename(columns={'pixelWater':'datawater'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_iloc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_Names = ['Latitude','Longitude','crime','Bathrooms','SQFT','Price','energySiteEUI']\n",
    "\n",
    "datacon = df_iloc[my_Names]\n",
    "datacon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datacon['energySiteEUI'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# energy = datacon['energySiteEUI']\n",
    "# temp = energy.values\n",
    "# plt.hist(temp,bins=50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Delete rows with zeros \n",
    "# dataNoZero = datacon[(datacon['energySiteEUI']==0) == False]\n",
    "# dataNoZero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "energy = dataNoZero['energySiteEUI']\n",
    "temp = energy.values\n",
    "plt.hist(temp,bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Delete rows with Outliers \n",
    "\n",
    "dataNoOutliers = dataNoZero[(dataNoZero['energySiteEUI']>1000) == False]\n",
    "\n",
    "energy = dataNoOutliers['energySiteEUI']\n",
    "temp = energy.values\n",
    "plt.hist(temp,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataNoOutliers['energySiteEUI'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = energy.values\n",
    "plt.hist(y,bins = 50,color=\"#FFBBBB\")\n",
    "plt.axvline(68.800000,c=\"green\")\n",
    "plt.axvline(130.900000,c=\"red\")\n",
    "plt.axvline(250.000000,c=\"green\")\n",
    "plt.xlabel(\"energyEUI\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlim(0, 1000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "fig = plt.figure(figsize=(35,10))\n",
    "\n",
    "#Project onto axes: 1, 2, 3\n",
    "ax1 = fig.add_subplot(1, 3, 1,  projection='3d')\n",
    "\n",
    "newData = pd.DataFrame()\n",
    "newData['Longitude'] = dataNoOutliers['Longitude']\n",
    "newData['Latitude'] = dataNoOutliers['Latitude']\n",
    "newData['y'] = y\n",
    "\n",
    "newData1 = newData[newData['y']<68.8]\n",
    "newData2 = newData[(newData['y']>68.8 )&(newData['y']<250)]\n",
    "newData3 = newData[250<newData['y']]\n",
    "\n",
    "\n",
    "ax1.scatter(newData1['Longitude'], newData1['Latitude'],newData1['y'], label='Low' , facecolors = \"gray\",edgecolors = \"blue\",alpha = 0.5, s=18)\n",
    "ax1.scatter(newData2['Longitude'], newData2['Latitude'],newData2['y'], label='Mid' , facecolors = \"#FFBBBB\",edgecolors = \"green\",alpha = 0.5, s=18)\n",
    "ax1.scatter(newData3['Longitude'], newData3['Latitude'],newData3['y'], label='High' , facecolors = \"gray\",edgecolors = \"red\",alpha = 0.5, s=18)\n",
    "\n",
    "\n",
    "ax1.set_xlabel('\\n'+'\\n' + 'Longitude')\n",
    "ax1.set_ylabel('\\n'+'\\n' +'Latitude')\n",
    "ax1.set_zlabel('\\n'+'\\n' +'Energy')\n",
    "ax1.set_title('Boston Energy use By Longitude & Latitude')\n",
    "ax1.legend(loc='lower left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SavePandasToCSV(d, path):\n",
    "    d.to_csv(path)\n",
    "    return \"done!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SavePandasToCSV(dataNoOutliers, \"energy.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
